{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24422a53",
   "metadata": {},
   "source": [
    "# Processing Real estate transactions dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install geodatasets\n",
    "!{sys.executable} -m pip install folium>=0.12\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install mapclassify\n",
    "!{sys.executable} -m pip install h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847adace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geodatasets\n",
    "import h3\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830cb22",
   "metadata": {},
   "source": [
    "## Downloading directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data contains lots of information (see below). We keep only the relevant ones for our needs \n",
    "relev_cols=['anneemut','datemut','valeurfonc','coddep','sbati','sterr','geompar_x','geompar_y','libtypbien']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING : the file is relatively large, so this can take some time\n",
    "# Online version \n",
    "url = 'https://minio.lab.sspcloud.fr/tomvxz/diffusion/transac.parquet'\n",
    "df_reduced = pd.read_parquet(url, columns=relev_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce334744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offline version if available. Run this if you have downloaded the file localy already for future uses\n",
    "#df_reduced = pd.read_parquet('transac.parquet',columns=relev_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bd361",
   "metadata": {},
   "source": [
    "## Dictionary of variables - Dataset DV3F (Cerema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b9516",
   "metadata": {},
   "source": [
    "Explaination from the variables come from here, they were formatted by ChatGPT : https://doc-datafoncier.cerema.fr/doc/dv3f/mutation. Most of them are useless in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e7a6a",
   "metadata": {},
   "source": [
    "This dataset comes from the **French Property Transaction Database (DVF – Demandes de Valeurs Foncières)** processed by **Cerema**. It records **real estate transactions carried out for consideration** (sales, exchanges, auctions).\n",
    "\n",
    "### 1. Identifiers and References\n",
    "These keys ensure row uniqueness or allow joins with other datasets (Land Registry / MAJIC files).\n",
    "\n",
    "| Column | Description |\n",
    "| :--- | :--- |\n",
    "| **`idmutation`** | Unique transaction identifier (generated by Cerema). |\n",
    "| `idmutinvar` | Stable identifier used to join with Land Registry (MAJIC) files. |\n",
    "| `idopendata` | Original identifier from the raw DVF file (DGFiP). |\n",
    "| `codservch` | Code of the Land Registration Office (SPF). |\n",
    "| `refdoc` | Publication reference (Volume / Number). |\n",
    "\n",
    "### 2. Transaction Date and Nature\n",
    "\n",
    "| Column | Description |\n",
    "| :--- | :--- |\n",
    "| **`datemut`** | Exact date of the transaction. |\n",
    "| `anneemut` | Year of the transaction. |\n",
    "| `moismut` | Month of the transaction. |\n",
    "| `idnatmut` | Code describing the nature of the transaction (1 = Sale, etc.). |\n",
    "| **`libnatmut`** | Label describing the nature (e.g. *Sale*, *Sale of a property under construction*). |\n",
    "| **`vefa`** | Boolean indicator: Sale of a Property Under Construction (new housing). |\n",
    "| `nbartcgi` | Number of tax code articles applied. |\n",
    "| `l_artcgi` | List of applicable tax code articles. |\n",
    "| `nbdispo` | Number of legal provisions included in the deed. |\n",
    "\n",
    "### 3. Geographic Location\n",
    "\n",
    "| Column | Description |\n",
    "| :--- | :--- |\n",
    "| `coddep` | Department code (e.g. 75, 59). |\n",
    "| `nbcomm` | Number of municipalities involved. |\n",
    "| `l_codinsee` | List of INSEE municipality codes. |\n",
    "| `nbsection` / `l_section` | Number and list of cadastral sections. |\n",
    "| `nbpar` / `l_idpar` | Number and list of parcel identifiers involved. |\n",
    "| `nbparmut` / `l_idparmut` | Number and list of parcels **actually transferred**. |\n",
    "| `geompar_x` / `geompar_y` | Geographic coordinates (centroids). |\n",
    "\n",
    "### 4. Price and Land (Plot Characteristics)\n",
    "\n",
    "| Column | Description |\n",
    "| :--- | :--- |\n",
    "| **`valeurfonc`** | **Total transaction value** (net of seller). *Sum for all properties included in the transaction.* |\n",
    "| `sterr` | Total land area (m²). |\n",
    "| `l_dcnt` | List of cadastral land areas. |\n",
    "| `nbsuf` | Number of land surfaces (link with Land Registry files). |\n",
    "\n",
    "### 5. Building Characteristics (General)\n",
    "\n",
    "| Column | Description |\n",
    "| :--- | :--- |\n",
    "| `codtypbien` | Property typology code (computed by Cerema). |\n",
    "| **`libtypbien`** | Typology label (e.g. *House*, *Existing apartment*, *Building land*). |\n",
    "| **`sbati`** | Total built surface area (m²) for all premises. |\n",
    "| `nblot` | Number of condominium lots. |\n",
    "| `nbvolmut` | Number of volumes transferred. |\n",
    "| `nblocmut` | Total number of premises transferred. |\n",
    "| `l_idlocmut` | List of premises identifiers. |\n",
    "\n",
    "### 6. Breakdown by Type of Premises\n",
    "Distribution of premises by category and associated surface areas.\n",
    "\n",
    "| Column (Count) | Column (Surface) | Description |\n",
    "| :--- | :--- | :--- |\n",
    "| `nblocmai` | `sbatmai` | Number and built area of **Houses**. |\n",
    "| `nblocapt` | `sbatapt` | Number and built area of **Apartments**. |\n",
    "| `nblocact` | `sbatact` | Number and built area of **Commercial / Activity premises**. |\n",
    "| `nblocdep` | – | Number of isolated **Outbuildings**. |\n",
    "\n",
    "### 7. Breakdown by Number of Rooms (Housing Units)\n",
    "Detail by number of main rooms.  \n",
    "*Note: `5pp` corresponds to “5 rooms or more”.*\n",
    "\n",
    "| Type | Counts | Surface Areas (m²) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Apartments** | `nbapt1pp` to `nbapt5pp` | `sapt1pp` to `sapt5pp` |\n",
    "| **Houses** | `nbmai1pp` to `nbmai5pp` | `smai1pp` to `smai5pp` |\n",
    "\n",
    "---\n",
    "\n",
    "> **Important note for analysis:**  \n",
    "> The **`valeurfonc`** variable represents the **total value of the transaction** (`idmutation`).  \n",
    "> If a single row includes multiple properties (e.g. a building with `nblocapt = 10` apartments), the recorded value corresponds to the **total price of the building**, not the price per apartment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d5ed9",
   "metadata": {},
   "source": [
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987f92d",
   "metadata": {},
   "source": [
    "### Removing weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for na values and non-relevant ones \n",
    "na_price = df_reduced['valeurfonc'].loc[df_reduced['valeurfonc'].isna()].count()\n",
    "print('Nan price: ' + na_price.astype(str))\n",
    "\n",
    "na_price = df_reduced['valeurfonc'].loc[df_reduced['valeurfonc']==0].count()\n",
    "print('Null price: ' + na_price.astype(str))\n",
    "\n",
    "zero_surf = df_reduced['sbati'].loc[df_reduced['sbati']==0].count()\n",
    "print('Transactions with 0 m2: '+ zero_surf.astype(str))\n",
    "\n",
    "nbr_trans = df_reduced['valeurfonc'].count()\n",
    "print('Number of transactions: '+nbr_trans.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241d1fc",
   "metadata": {},
   "source": [
    "This is a lot of transactions, but with 0 as the size of the built part, there are either errors or terrains such as fields. So we decide to remove them. Keeping them creates also very weird results in what follows, which is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following previous anaylysis, we clean the data \n",
    "\n",
    "# Removing irrelevant transactions based on price\n",
    "view_price = df_reduced.loc[:,'valeurfonc']\n",
    "view_geo = df_reduced.loc[:,'geompar_x']\n",
    "view_surf = df_reduced.loc[:,'sbati'] \n",
    "filter =  (view_price.isna()) | (view_geo.isna()) | (view_surf == 0) | (view_price == 0)\n",
    "df_cleaned = df_reduced[~filter].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check the other columns \n",
    "for col in relev_cols:\n",
    "    print(df_cleaned[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check for weird case that could happen else than na values\n",
    "print(df_cleaned['anneemut'].min(),df_cleaned['anneemut'].max()) #Checking the range of years\n",
    "print(df_cleaned['datemut'].min(),df_cleaned['datemut'].max()) #Checking concistency with years\n",
    "print(df_cleaned['valeurfonc'].min(),df_cleaned['valeurfonc'].max()) #Checking range of prices\n",
    "print(df_cleaned['sbati'].min(),df_cleaned['sbati'].max()) #Checkin range of surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c5230",
   "metadata": {},
   "source": [
    "We see that the range of prices is very large and still has values close to 0 (which probably corresponds to things like donation), so we want to remove extreme ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4150da6",
   "metadata": {},
   "source": [
    "### Checking the values of department codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['coddep'].unique() # Checking coherent dep codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e76562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced[\"coddep\"].nunique()\n",
    "#for a weird reason there seems to be only 97 departments in this dataset, without further time to inquire about the reasons of this, we will just ignore this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0503222",
   "metadata": {},
   "source": [
    "### Handling the values of transactions to remove extreme cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a29033",
   "metadata": {},
   "source": [
    "We first look at the repartition of the log price of the transactions. The log allows to get a readable graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins with numpy for faster computations\n",
    "counts, bin_edges = np.histogram(np.log(df_cleaned['valeurfonc']), bins=100)\n",
    "\n",
    "# We look at a barplot of the log of valeurfonc to have an idea of the values\n",
    "plt.bar(bin_edges[:-1], counts, width=np.diff(bin_edges), align='edge')\n",
    "plt.xlim([0,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e041b920",
   "metadata": {},
   "source": [
    "Based on this, we decide to remove transactions of which the log of price is above 15 or below 7.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859655ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extreme price values\n",
    "df_cleaned = df_cleaned[(np.log(df_cleaned['valeurfonc'])<=15) & (np.log(df_cleaned['valeurfonc'])>=7.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33efbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins with numpy for faster computations\n",
    "counts, bin_edges = np.histogram(np.log(df_cleaned['valeurfonc']), bins=100)\n",
    "\n",
    "# We look at a barplot of the log of valeurfonc to have an idea of the values\n",
    "plt.bar(bin_edges[:-1], counts, width=np.diff(bin_edges), align='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15610613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins with numpy for faster computations\n",
    "counts, bin_edges = np.histogram(np.log(df_cleaned['sbati']), bins=100)\n",
    "\n",
    "# We look at a barplot of the log of valeurfonc to have an idea of the values\n",
    "plt.bar(bin_edges[:-1], counts, width=np.diff(bin_edges), align='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1874ac",
   "metadata": {},
   "source": [
    "### Creation of price per meter squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29748baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since valeurfonc is highly dependant on the size of the building/house sold, we look at price/m2\n",
    "# We choose to divide first by the built surface (other approches to come)\n",
    "df_cleaned.loc[:,'p/m2']=df_cleaned['valeurfonc']/df_cleaned['sbati']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af71920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins with numpy for faster computations\n",
    "counts, bin_edges = np.histogram(np.log(df_cleaned['p/m2']), bins=100)\n",
    "\n",
    "# We look at a barplot of the log of valeurfonc to have an idea of the values\n",
    "plt.bar(bin_edges[:-1], counts, width=np.diff(bin_edges), align='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66932c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the values based on the graph\n",
    "filter_pm2 = (np.log(df_cleaned['p/m2'])>=3) & (np.log(df_cleaned['p/m2'])<=10)\n",
    "df_cleaned = df_cleaned[filter_pm2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c2add",
   "metadata": {},
   "source": [
    "The repartition makes now much more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bins with numpy for faster computations\n",
    "counts, bin_edges = np.histogram(df_cleaned['p/m2'], bins=100)\n",
    "\n",
    "# We look at a barplot of the log of valeurfonc to have an idea of the values\n",
    "plt.bar(bin_edges[:-1], counts, width=np.diff(bin_edges), align='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef58a65",
   "metadata": {},
   "source": [
    "### Usage of building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['libtypbien'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb0ad1",
   "metadata": {},
   "source": [
    "We also have access to the nature of the good being traded, which we could potentially use to be more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf16d2",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1eaf3",
   "metadata": {},
   "source": [
    "We create the geopandas dataframe to easily draw maps. The caveat is that the given coordinates in the dataframe use different systems depending on the zone. For instance, in France, the system used is Lambert 93 and we have to convert that to the classic GPS system that is widely used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c167f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geopandas\n",
    "\n",
    "projections = {\n",
    "    \"Metro\":  \"EPSG:2154\",  # Lambert 93 (France entière hors DOM)\n",
    "    \"971\":    \"EPSG:5490\",  # Guadeloupe (UTM 20N)\n",
    "    \"972\":    \"EPSG:5490\",  # Martinique (UTM 20N)\n",
    "    \"973\":    \"EPSG:2972\",  # Guyane (UTM 22N)\n",
    "    \"974\":    \"EPSG:2975\",  # La Réunion (UTM 40S)\n",
    "    \"976\":    \"EPSG:4471\",   # Mayotte\n",
    "}\n",
    "\n",
    "parts = []\n",
    "\n",
    "#Handling each zones (DOM/TOM have specific zones)\n",
    "for zone, epsg_code in projections.items():\n",
    "    if zone == \"Metro\":\n",
    "        # Everything that is not a DOM/TOM\n",
    "        subset = df_cleaned.loc[~((df_cleaned['coddep'].str.startswith('97')) | (df_cleaned['coddep'].isin(['13', '26'])))]\n",
    "    else:\n",
    "        # Take specific zone\n",
    "        subset = df_cleaned.loc[df_cleaned['coddep'] == zone]\n",
    "    \n",
    "    if not subset.empty:\n",
    "        gdf_subset = gpd.GeoDataFrame(\n",
    "            subset,\n",
    "            geometry=gpd.points_from_xy(subset['geompar_x'], subset['geompar_y']),\n",
    "            crs=epsg_code\n",
    "        )\n",
    "        \n",
    "        # Converting to GPS coordinates\n",
    "        gdf_subset = gdf_subset.to_crs(\"EPSG:4326\")\n",
    "        \n",
    "        parts.append(gdf_subset)\n",
    "\n",
    "gdf_final = pd.concat(parts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ed3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check that our geometries are non-empty\n",
    "print(gdf_final.geometry.is_empty.sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e88c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final.sample(100).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047e5a5",
   "metadata": {},
   "source": [
    "## Per department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7500b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We standardize the department (adding 0 at the begining if only one number : 1 -> 01)\n",
    "gdf_final[\"coddep\"] = gdf_final[\"coddep\"].str.zfill(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57973bfa",
   "metadata": {},
   "source": [
    "### Number of real_estate transactions per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we groupby for each department by numbers of transactions\n",
    "nb_transac_per_dep = gdf_final.groupby(\"coddep\").size().reset_index(name='Number_transactions')\n",
    "nb_transac_per_dep.to_csv(\"nb_transac_per_dep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting population data from insee\n",
    "def deps_pop_init():\n",
    "    deps_pop = pd.read_excel(\"https://www.insee.fr/fr/statistiques/fichier/2012713/TCRD_004.xlsx\")\n",
    "    deps_pop.columns = deps_pop.iloc[2]\n",
    "    deps_pop = deps_pop.iloc[3:]\n",
    "    deps_pop = deps_pop.reset_index()\n",
    "    deps_pop.columns = [\"to_del\", \"code\", \"deps_name\", \"2025\", \"share_pop\",\"2022\", \"2016\",\"2011\",\"1999\"]\n",
    "    deps_pop.set_index(\"code\")\n",
    "    deps_pop = deps_pop.loc[0:101,[\"code\",\"2011\",\"2025\"]]\n",
    "    return deps_pop\n",
    "\n",
    "deps_pop = deps_pop_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge the data and get population data\n",
    "def add_department_pop(df):\n",
    "    df = df.reset_index()\n",
    "    df = df.merge(\n",
    "        deps_pop[[\"code\", \"2011\", \"2025\"]],\n",
    "        left_on=\"coddep\",\n",
    "        right_on=\"code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    df = df.drop(columns=[\"code\"]).set_index(\"coddep\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding name to department\n",
    "deps = gpd.read_file(\"https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/departements.geojson\")\n",
    "\n",
    "def add_department_name(df):\n",
    "    df = df.merge(\n",
    "        deps[[\"code\", \"nom\"]],\n",
    "        left_on=\"coddep\",\n",
    "        right_on=\"code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df[\"coddep\"] = (\n",
    "        df[\"code\"].astype(str) + \" - \" + df[\"nom\"]\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .drop(columns=[\"code\", \"nom\"])\n",
    "        .set_index(\"coddep\")\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd03ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating transaction frequency\n",
    "nb_transac_per_dep = nb_transac_per_dep[[\"coddep\",\"Number_transactions\"]]\n",
    "nb_transac_per_dep.rename(columns={\"coddep\": \"Code du département du lieu des travaux - Code de la zone\"})\n",
    "nb_transac_per_pop_dep = add_department_pop(nb_transac_per_dep)\n",
    "nb_transac_per_pop_dep[\"transac_freq\"] =  nb_transac_per_pop_dep[\"Number_transactions\"]/nb_transac_per_pop_dep[\"2025\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_department_name(nb_transac_per_pop_dep[\"transac_freq\"].sort_values(ascending=False).to_frame().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547499c0",
   "metadata": {},
   "source": [
    "Number of real estate transactions per population could be an indicator of how intensive is the trading in a place, which could be an indicator of speculation, defined as buying a property to make monetary profit from the variation of price. \n",
    "However, population does not take into account secondary residency owned by non resident of a department. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374d471",
   "metadata": {},
   "source": [
    "### Growth of p/m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_pm2_per_dep = gdf_final.groupby(\"coddep\")[\"p/m2\"].median().to_frame()\n",
    "add_department_name(median_pm2_per_dep[\"p/m2\"].sort_values(ascending=False).to_frame().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_dep = gdf_final.groupby([\"coddep\",\"anneemut\"])[\"p/m2\"].median().unstack(1)\n",
    "pm2_growth_per_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68bb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_dep = pm2_growth_per_dep.pct_change(axis=1)\n",
    "pm2_growth_per_dep = pm2_growth_per_dep.quantile(0.9,axis=1).to_frame()\n",
    "pm2_growth_per_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_department_name(pm2_growth_per_dep[0].sort_values(ascending=False).to_frame()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_pop_per_dep = add_department_pop(pm2_growth_per_dep)\n",
    "pm2_growth_pop_per_dep[\"pop_growth\"] = (pm2_growth_pop_per_dep[\"2025\"]-pm2_growth_pop_per_dep[\"2011\"])/pm2_growth_pop_per_dep[\"2025\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d34c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    pm2_growth_pop_per_dep[\"pop_growth\"],\n",
    "    pm2_growth_pop_per_dep[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350005f7",
   "metadata": {},
   "source": [
    "Departments where there was high increases of prices during the period are not departments that had high level of population growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87441cff",
   "metadata": {},
   "source": [
    "What if we look at the \"average\" (we will here take median as the dataset contains extremely low and extremely high values) growth rate of prices during the period ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d03cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_dep = gdf_final.groupby([\"coddep\",\"anneemut\"])[\"p/m2\"].median().unstack(1)\n",
    "pm2_growth_per_dep = pm2_growth_per_dep.pct_change(axis=1)\n",
    "pm2_growth_per_dep = pm2_growth_per_dep.quantile(0.5,axis=1).to_frame()\n",
    "add_department_name(pm2_growth_per_dep[0.5].sort_values(ascending=False).to_frame()).head(10)\n",
    "pm2_growth_pop_per_dep = add_department_pop(pm2_growth_per_dep)\n",
    "pm2_growth_pop_per_dep[\"pop_growth\"] = (pm2_growth_pop_per_dep[\"2025\"]-pm2_growth_pop_per_dep[\"2011\"])/pm2_growth_pop_per_dep[\"2025\"]\n",
    "plt.scatter(\n",
    "    pm2_growth_pop_per_dep[\"pop_growth\"],\n",
    "    pm2_growth_pop_per_dep[0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ff56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_department_name(pm2_growth_pop_per_dep.loc[pm2_growth_pop_per_dep[0.5]>0.06])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa9768",
   "metadata": {},
   "source": [
    "These are the departments where median price growth over the period was the highest, despite normal or even negative population growth. These departments do not seem to have any distinctive feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b03d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_dep = gdf_final.groupby([\"coddep\",\"anneemut\"])[\"p/m2\"].median().unstack(1)\n",
    "pm2_growth_per_dep.iloc[18:45,]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f71b7",
   "metadata": {},
   "source": [
    "We remark that these are departments where there are not a lot of datas : the outliers seems to be statistical artefact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfcd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_dep = gdf_final.groupby([\"coddep\",\"anneemut\"])[\"p/m2\"].median().unstack(1)\n",
    "pm2_growth_per_dep = pm2_growth_per_dep.pct_change(axis=1)\n",
    "pm2_growth_per_dep = pm2_growth_per_dep.mean(axis=1).to_frame()\n",
    "add_department_name(pm2_growth_per_dep[0].sort_values(ascending=False).to_frame()).head(10)\n",
    "pm2_growth_pop_per_dep = add_department_pop(pm2_growth_per_dep)\n",
    "pm2_growth_pop_per_dep[\"pop_growth\"] = (pm2_growth_pop_per_dep[\"2025\"]-pm2_growth_pop_per_dep[\"2011\"])/pm2_growth_pop_per_dep[\"2025\"]\n",
    "\n",
    "plt.scatter(\n",
    "    pm2_growth_pop_per_dep[\"pop_growth\"],\n",
    "    pm2_growth_pop_per_dep[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9177a",
   "metadata": {},
   "source": [
    "## Per hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuration\n",
    "\n",
    "resolution = 7\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# OPTIMISATION 1 : Assigning a hexagon to every transaction \n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# On extrait les colonnes en tableaux NumPy purs (.values)\n",
    "# C'est beaucoup plus rapide que d'accéder à geometry.x ligne par ligne\n",
    "lats = gdf_final.geometry.y.values\n",
    "lons = gdf_final.geometry.x.values\n",
    "\n",
    "# On utilise une compréhension de liste avec zip\n",
    "# C'est la méthode standard la plus rapide en Python pur\n",
    "gdf_final['h3_index'] = [\n",
    "    h3.latlng_to_cell(lat, lon, resolution) \n",
    "    for lat, lon in zip(lats, lons)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# OPTIMISATION 2 : Reconstructing the geometry of the h3-hexagon\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def hex_to_poly_optimized(h3_id):\n",
    "    # cell_to_boundary renvoie ((lat, lon), (lat, lon)...)\n",
    "    points = h3.cell_to_boundary(h3_id)\n",
    "    # Inversion (Lat, Lon) -> (Lon, Lat) + Création Polygon\n",
    "    return Polygon([(lng, lat) for lat, lng in points])\n",
    "\n",
    "def display_hexagon_map(df_counts,variable):\n",
    "    # Ici aussi, on évite .apply() pour utiliser une boucle de liste directe\n",
    "    #we create a geodataframe that assign a geometry to every hexagon\n",
    "    gdf_h3 = gpd.GeoDataFrame(\n",
    "        df_counts,\n",
    "        geometry=[hex_to_poly_optimized(h_id) for h_id in df_counts['h3_index'].values],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    #displaying the hexagon\n",
    "    m = gdf_h3.explore(\n",
    "        column=variable,\n",
    "        cmap=\"inferno\",\n",
    "        style_kwds={\"fillOpacity\": 0.6, \"weight\": 0},\n",
    "        tiles=\"CartoDB positron\"\n",
    "    )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40ed30",
   "metadata": {},
   "source": [
    "### Number of transactions per hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"Number_transactions\"\n",
    "df_counts = gdf_final.groupby('h3_index').size().reset_index(name=variable)\n",
    "display_hexagon_map(df_counts, variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee2dd1",
   "metadata": {},
   "source": [
    "### Median price of a transation per hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"Median price of transactions\"\n",
    "df_counts = gdf_final.groupby('h3_index')['valeurfonc'].median().reset_index(name=variable)\n",
    "display_hexagon_map(df_counts, variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b9c69",
   "metadata": {},
   "source": [
    "### Median p/m2 per hexagon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08005a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final = gdf_final[gdf_final['p/m2'] < np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = \"Median p/m2\"\n",
    "df_counts = gdf_final.groupby('h3_index')['p/m2'].median().reset_index(name=variable)\n",
    "display_hexagon_map(df_counts, variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f13aa",
   "metadata": {},
   "source": [
    "### Time-series analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c74d8a",
   "metadata": {},
   "source": [
    "#### Nb of constructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99199d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final.groupby('h3_index').size().reset_index(name='Number_transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1ef688",
   "metadata": {},
   "source": [
    "#### Median p/m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final = gdf_final.loc[gdf_final['p/m2']<50000,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df070bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_final = gdf_final[gdf_final['p/m2'] < np.inf]\n",
    "gdf_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_hex = gdf_final.groupby(['h3_index','anneemut'])['p/m2'].median().unstack(1)\n",
    "pm2_growth_per_hex =pm2_growth_per_hex.pct_change(axis=1)\n",
    "# log growth : pm2_growth_per_hex = np.log1p(pm2_growth_per_hex).diff(axis=1)\n",
    "\n",
    "    \n",
    "pm2_growth_per_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_hex = pm2_growth_per_hex.median(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2971ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm2_growth_per_hex.to_csv(\"pm2_growth_per_hex.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
